{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project Title: Custom Tabular LLM Chatbot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell for importing required modules\n",
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    "\n",
    "from langchain.text_splitter import MarkdownTextSplitter\n",
    "from langchain.docstore.document import Document\n",
    "import tiktoken\n",
    "import openai\n",
    "\n",
    "import time \n",
    "import os \n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Pandas limitations to display entire output\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV file and verify the content\n",
    "df = pd.read_csv(\"EPIQ.csv\", index_col = None, header = 3)\n",
    "\n",
    "# Get rid of NA values \n",
    "df = df.dropna(axis=1, how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract metadata\n",
    "metadata = {\n",
    "    'columns': list(df.columns),\n",
    "    'num_entries': len(df),\n",
    "    'example_entry': df.iloc[0].to_dict()  \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to markdown\n",
    "mkdn = tabulate(df, tablefmt=\"pipe\", headers=\"keys\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check total length of the input in tokens\n",
    "def calculate_tokens(text, encoding):\n",
    "    encoding = tiktoken.get_encoding(encoding)\n",
    "    num_tokens = len(encoding.encode(text))\n",
    "    return num_tokens\n",
    "\n",
    "calculate_tokens(mkdn, \"cl100k_base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_docs(text, metadata):\n",
    "    doc_chunks = []\n",
    "    text_splitter = MarkdownTextSplitter(chunk_size=250, chunk_overlap=0)  # only 1 row per doc, otherwise - parsing errors in prompting!!!\n",
    "    chunks = text_splitter.split_text(text)\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        doc = Document(page_content=chunk, metadata=metadata)\n",
    "        doc_chunks.append(doc)\n",
    "    return doc_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = text_to_docs(mkdn, metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del docs[0]    # removing the first doc which only contains headers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_file_num(directory, base_filename):\n",
    "    # get a list of all existing filenames\n",
    "    files = os.listdir(directory)\n",
    "    \n",
    "    # filter to only those that match the filename pattern\n",
    "    base_filename = f'{base_filename}_'\n",
    "    matching_files = [f for f in files if f.startswith(base_filename)]\n",
    "    \n",
    "    # extract the numbers from these filenames\n",
    "    nums = [int(re.search(r'(\\d+)', f).group()) for f in matching_files if re.search(r'(\\d+)', f)]\n",
    "\n",
    "    # return the max number + 1, or 1 if no existing files\n",
    "    return max(nums) + 1 if nums else 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store conversation history in Excel for further reference \n",
    "def xlsx_log(file_name, user_message, bot_response):\n",
    "\n",
    "    excel_log = pd.DataFrame({'User': [user_message], 'Bot': [bot_response]})\n",
    "    num = get_next_file_num('.', file_name)\n",
    "        \n",
    "    excel_log.to_csv(f'{file_name}_{num}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = \"your_key\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option alternative to relevance score - proved to be faster and more efficient since we are dealing with unique identifiers of similar structure\n",
    "def extract_details(query):\n",
    "    match = re.search(r\"FUS\\d+\", query)                   # pattern match on all FUS-prefixed options\n",
    "    return match.group(0) if match else None\n",
    "\n",
    "def check_relevance(doc, user_option):\n",
    "    return user_option in doc.page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chatbot():\n",
    "    # Activate chatbot\n",
    "    while True:\n",
    "        user_message = input(\"User: \")\n",
    "        if user_message.lower() == \"quit\":\n",
    "            break\n",
    "\n",
    "        # Calculate relevance scores and pick the most suitable chunk for response  - PREVIOUS APPROACH\n",
    "        relevance_scores = []\n",
    "\n",
    "        user_option = extract_details(user_message)  \n",
    "\n",
    "        for index, doc in enumerate(docs):\n",
    "            if user_option and user_option in doc.page_content:\n",
    "                relevance_score = 10  \n",
    "            else:\n",
    "                relevance_score = 0  \n",
    "\n",
    "            relevance_scores.append(relevance_score)\n",
    "\n",
    "        most_relevant_chunk_index = relevance_scores.index(max(relevance_scores))\n",
    "        most_relevant_chunk = docs[most_relevant_chunk_index]\n",
    "\n",
    "        print(most_relevant_chunk)\n",
    "\n",
    "        # Prompt using Chain-of-Thought technique\n",
    "\n",
    "        metadata_info = (\n",
    "                f\"The document is structured in a tabular format with columns such as {', '.join(doc.metadata['columns'])}. \"\n",
    "                f\"Each row in the table represents a unique dataset, where entries are arranged following a similar structure: (row number)| Option | Name | AFI | APA | BNL | CEE | DAC | FRA | GRC | IBE | IIG | ISC | JPN | LAT | MET | NAM | NOR | RCA | UKI | Sum. \"\n",
    "                f\"For example, one entry might be formatted like this: '| 4 | FUS6140 | CIVCO eTRAX Sensor 12G | 0 | 0 | 0 | 1 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 2 |'. \"\n",
    "                f\"This example shows how each column is filled with specific data points relevant to each dataset. \"\n",
    "                f\"Note that the actual content will be structured similarly, ensuring that each entry is clearly delineated by these columns.\"\n",
    "            )\n",
    "        \n",
    "        # Specific examples in the prompt are key to successful execution. Tabular data requires a lot of handholding!\n",
    "        response_prompt = (f\"To address the query '{user_message}', examine the document which follows this metadata: {metadata_info}.\" \n",
    "                           f\"Identify which of the columns are most likely to contain relevant information. Analyze the data, focusing on these columns, \" \n",
    "                           f\"to locate and extract the precise information needed. Extract required information from this section: \\\"{most_relevant_chunk.page_content}\\.\"\n",
    "                           f\"Your response should follow this example: For option FUS6132 APA value is 2. If requested all values for an option, give only all columns that do not equal 0.\"\n",
    "                           f\"Your response should clearly indicate which columns are relevant and their corresponding values, similar to this example: \"\n",
    "                           f\"'For option FUS9170, the relevant columns and their values are APA: 13, CEE: 2, DAC: 2, GRC: 27, IIG: 1, ISC: 1, LAT: 1, MET: 7, NAM: 319, RCA: 1, Sum: 374.'\")\n",
    "\n",
    "        # Must redo entire structure of the chatbot if want to integrate summary statistics due to parsing method. \n",
    "\n",
    "        chat_response = openai.Completion.create(\n",
    "            model=\"gpt-3.5-turbo-instruct\",\n",
    "            prompt=response_prompt,\n",
    "            max_tokens=150\n",
    "        )\n",
    "\n",
    "        chat_message = chat_response['choices'][0]['text'].strip()\n",
    "        print(f\"Bot: {chat_message}\")\n",
    "\n",
    "        xlsx_log(\"chat_log\", user_message, chat_message)\n",
    "\n",
    "        # Modify as needed to make sure API calls don't exceed the limit\n",
    "        time.sleep(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chatbot()  # Note that outputs tend to get more precise later in the session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
